{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad37b7e",
   "metadata": {},
   "source": [
    "Titanic data project \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data manipulation library \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Titanic.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4088e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking dataset information \n",
    "# three main charater show here column not null & Dtype\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f382780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking null values \n",
    "import matplotlib.pyplot as plt\n",
    "df.isnull().sum().sort_values(ascending= True).plot(kind ='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation strategy \n",
    "'''  \n",
    "this is used for impute values in null space\n",
    "'''\n",
    "import pandas as pd\n",
    "df\n",
    "print('missing value present in age column: ', df['age'].isnull().sum()/len \n",
    "      (df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].median(),df['age'].mean() # showing values in age column mean and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values and fill null value place\n",
    "# always used in data analysis for data cleaning \n",
    "df['age'].fillna(df['age'].median(),inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9203779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fill values in place of null in embarkd colmn \n",
    "df['embarked'].fillna('S',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('missing value present in age column: ', df['embarked'].isnull().\n",
    "      sum()/len (df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show values in embarked colmn\n",
    "df['embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregate numerical colmn and categorical colm\n",
    "categorical_col = df.select_dtypes(include= 'object')\n",
    "numerical_col = df.select_dtypes(exclude= 'object') #only numerical show\n",
    "numerical_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelEncoder used for categoricla colmn convert into numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder\n",
    "for i in categorical_col.columns:\n",
    "    df[i]=le.fit_transform(df[i])\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b644d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting boolean datatype into number int\n",
    "df['alone'] = df['alone'].astype(int)\n",
    "df['alone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df['alone'] = df['alone'].astype(int)\n",
    "df['alone'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de9401",
   "metadata": {},
   "source": [
    "Data Leakage and Scaling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalling technique and Data Leakage used for model bldg\n",
    "''' \n",
    "1.Min-Max scaler : When dataset is non normal distribution mean!= Median\n",
    "2.stdScaler : when dataset is normal distribution \n",
    "3.Robust Scaler : When dataset is non normal distributed and \n",
    "model is sensative of outliers i.e when model is overfit\n",
    "\n",
    "Data Leakage\n",
    "\n",
    "step 1: Split dataset into x and y \n",
    "         X: Independent columns\n",
    "         y: Dependent columns / Target columns\n",
    "step 2: Split dataset into train and test\n",
    "        x_train : Seen Data : 70% \n",
    "        x_test : unSeen Data :30%\n",
    "        ---------------------------\n",
    "        y_train : Seen data : 70%\n",
    "        y_test : unseenSeen : 30%\n",
    "step 3: If you are solving classification model/Recommandation Model then\n",
    "        use Imbalance Techniques \n",
    "        A] Over sampling technique:\n",
    "            1. SMOTE 2. SMOTEN 3. SMOTENC\n",
    "        B] Under sampling technique:\n",
    "            1. ClusterCentroid 2.Allknn\n",
    "Step 4: use proper scaling techniques based on dataset...\n",
    "        1.Min-Max scaler : When dataset is non normal distribution mean!= Median\n",
    "        2.stdScaler : when dataset is normal distribution \n",
    "        3.Robust Scaler : When dataset is non normal distributed and \n",
    "        model is sensative of outliers    \n",
    "step 5 : Model building '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78862b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in titanic dataset target column is imbalanced in nature\n",
    "#so hence use imbalance technique as this model is classification type\n",
    "import pandas as pd\n",
    "import seaborn as sns  # Titanic dataset is available in seaborn\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Now check the target column imbalance\n",
    "print(df['survived'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aca497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 \n",
    "X = df.drop(columns='survived' , axis=1)\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37543c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,\n",
    "random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "X_train,y_train = sm.fit_resample(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bca3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4 \n",
    "#Scaling technique\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c66a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1137a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  check why model accuracy low at 78%\n",
    "#minimum number of rows required for machine learning model to built =\n",
    "#  = 20 * No of Independent columns\n",
    "import seaborn as sns\n",
    "sns.regplot(x =y_test, y=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c863853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalePrice'].median,df['SalePrice'].mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
